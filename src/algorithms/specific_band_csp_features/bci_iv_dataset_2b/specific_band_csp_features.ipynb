{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/mauricio/development/environments/anaconda3/envs/motor-imagery/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from src.data_preparation.data_preparation import read_eeg_file\n",
    "from scipy import signal\n",
    "from scipy import linalg\n",
    "from scipy.integrate import simps\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pywt\n",
    "import pyriemann.utils.mean as rie_mean\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declaration some parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "FS = 250\n",
    "TIME_LENGTH = 750\n",
    "TIME_WINDOW = 500\n",
    "DATA_FOLDER = \"data/bci-csp-based/bci-iv-dataset-2b\"\n",
    "CSP_COMPONENTS = 2\n",
    "WAVELET = \"coif1\"\n",
    "K_FOLD = 10\n",
    "METRIC_COVARIANCE_ESTIMATION = \"euclid\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the subjects object and a dictionary to store the accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "subjects = range(1, 10)\n",
    "subjects_set = set(subjects)\n",
    "accuracies = {\n",
    "    \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the bandpass filter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sos = signal.cheby2(10, 50, [7, 30], analog=False, btype=\"band\", output=\"sos\", fs=FS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to generate the common spatial filter's based on the test data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def compute_spatial_filters(left_data, right_data):\n",
    "    n_channels = left_data.shape[2]\n",
    "    cov_shape = (n_channels, n_channels)\n",
    "            \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_left_trials = left_data.shape[0]\n",
    "    cov = np.zeros((n_left_trials, *cov_shape))\n",
    "    for n_trial in range(n_left_trials):\n",
    "        trial = signal.sosfilt(sos, left_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_1 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "    \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_right_trials = right_data.shape[0]\n",
    "    cov = np.zeros((n_right_trials, *cov_shape))\n",
    "    for n_trial in range(n_right_trials):\n",
    "        trial = signal.sosfilt(sos, right_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_2 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "    \n",
    "    # Solve the generalized eigenvalue problem\n",
    "    n_pairs = CSP_COMPONENTS//2\n",
    "    w, vr = linalg.eig(cov_1, cov_2, right=True)\n",
    "    w = np.abs(w)\n",
    "    sorted_indexes = np.argsort(w)\n",
    "    chosen_indexes = np.zeros(2*n_pairs).astype(int)\n",
    "    chosen_indexes[0:n_pairs] = sorted_indexes[0:n_pairs]\n",
    "    chosen_indexes[n_pairs:2*n_pairs] = sorted_indexes[-n_pairs:]\n",
    "    \n",
    "    return vr[:, chosen_indexes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    trials = X.shape[0]\n",
    "    F = np.zeros((trials, 2, CSP_COMPONENTS))\n",
    "    for n_trial in range(trials):\n",
    "        trial = X[n_trial]\n",
    "        z = np.dot(np.transpose(W), np.transpose(trial))\n",
    "        z = signal.sosfilt(sos, z, axis=1)\n",
    "        \n",
    "        # Calculate the wavelet features\n",
    "        for n_feature in range(CSP_COMPONENTS):\n",
    "            alpha_band, beta_band = pywt.dwt(z[n_feature], WAVELET)\n",
    "            F[n_trial, 0, n_feature] = np.sum(np.abs(beta_band) ** 2)\n",
    "\n",
    "        # Calculate the frequency-domain features\n",
    "        psd_window_size = 100\n",
    "        psd_window_overlap = psd_window_size//2\n",
    "        low, high = 13, 30\n",
    "        for n_feature in range(CSP_COMPONENTS):\n",
    "            freqs, psd = signal.welch(z[n_feature], fs=FS, window=\"hann\",\n",
    "                                     nperseg=psd_window_size, noverlap=psd_window_overlap)\n",
    "            beta_freqs = np.logical_and(freqs >= low, freqs <= high)\n",
    "            freq_res = freqs[1] - freqs[0]\n",
    "            F[n_trial, 1, n_feature] = simps(psd[beta_freqs], dx=freq_res)\n",
    "        \n",
    "    return F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterate on the subjects applying the algorithm, validating the results using the technique 10-fold cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Subject:  1\n",
      "Subject:  2\n",
      "Subject:  3\n",
      "Subject:  4\n",
      "Subject:  5\n",
      "Subject:  6\n",
      "Subject:  7\n",
      "Subject:  8\n",
      "Subject:  9\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    print(\"Subject: \", subject)\n",
    "\n",
    "    # Load data\n",
    "    left_data_file = f\"{DATA_FOLDER}/left-hand-subject-{subject}.csv\"\n",
    "    right_data_file = f\"{DATA_FOLDER}/right-hand-subject-{subject}.csv\"\n",
    "    data = read_eeg_file(left_data_file, right_data_file, TIME_LENGTH, TIME_WINDOW)\n",
    "    \n",
    "    W = compute_spatial_filters(data.X[data.labels == 0], data.X[data.labels == 1])\n",
    "    \n",
    "    subject_index = subject - 1\n",
    "    cv = StratifiedKFold(n_splits=K_FOLD, shuffle=False)\n",
    "    for (k, (train_index, test_index)) in enumerate(cv.split(data.X, data.labels)):\n",
    "        X_train, X_test = data.X[train_index], data.X[test_index]\n",
    "        y_train, y_test = data.labels[train_index], data.labels[test_index]\n",
    "        \n",
    "        # Feature extraction\n",
    "        features_train = extract_features(X_train)\n",
    "        features_test = extract_features(X_test)\n",
    "    \n",
    "        len_features = features_train.shape[1] * features_train.shape[2]\n",
    "        features_train = np.reshape(features_train, newshape=(features_train.shape[0], len_features))\n",
    "        features_test = np.reshape(features_test, newshape=(features_test.shape[0], len_features))\n",
    "\n",
    "        # Feature normalization\n",
    "        features_train = stats.zscore(features_train, axis=0)\n",
    "        features_test = stats.zscore(features_test, axis=0)\n",
    "        \n",
    "        # GNB classifier\n",
    "        gnb = GaussianNB(priors=[.5, .5], var_smoothing=1.0)\n",
    "        gnb.fit(features_train, y_train)\n",
    "        gnb_predictions = gnb.predict(features_test)\n",
    "        gnb_accuracy = accuracy_score(y_test, gnb_predictions)\n",
    "        accuracies[\"GNB\"][subject_index][k] = gnb_accuracy\n",
    "\n",
    "        # SVM classifier\n",
    "        svm = SVC(C=.8, kernel=\"rbf\")\n",
    "        svm.fit(features_train, y_train)\n",
    "        svm_predictions = svm.predict(features_test)\n",
    "        svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "        accuracies[\"SVM\"][subject_index][k] = svm_accuracy\n",
    "\n",
    "        # LDA classifier\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(features_train, y_train)\n",
    "        lda_predictions = lda.predict(features_test)\n",
    "        lda_accuracy = accuracy_score(y_test, lda_predictions)\n",
    "        accuracies[\"LDA\"][subject_index][k] = lda_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the accuracies obtained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "GNB\n",
      "\tSubject 1 average accuracy: 66.5351 +/- 8.3329\n",
      "\tSubject 2 average accuracy: 56.2739 +/- 5.9932\n",
      "\tSubject 3 average accuracy: 48.8827 +/- 3.4541\n",
      "\tSubject 4 average accuracy: 86.4140 +/- 6.8585\n",
      "\tSubject 5 average accuracy: 79.9885 +/- 4.9253\n",
      "\tSubject 6 average accuracy: 72.9636 +/- 7.0589\n",
      "\tSubject 7 average accuracy: 68.3571 +/- 14.8194\n",
      "\tSubject 8 average accuracy: 70.8198 +/- 13.5897\n",
      "\tSubject 9 average accuracy: 75.5081 +/- 7.0596\n",
      "\tAverage accuracy: 69.5270 +/- 13.9386\n",
      "SVM\n",
      "\tSubject 1 average accuracy: 69.3884 +/- 5.7522\n",
      "\tSubject 2 average accuracy: 57.1450 +/- 4.3352\n",
      "\tSubject 3 average accuracy: 53.3518 +/- 6.2969\n",
      "\tSubject 4 average accuracy: 91.5207 +/- 5.1103\n",
      "\tSubject 5 average accuracy: 82.4268 +/- 7.2987\n",
      "\tSubject 6 average accuracy: 76.5939 +/- 3.8371\n",
      "\tSubject 7 average accuracy: 70.7131 +/- 12.9112\n",
      "\tSubject 8 average accuracy: 74.0351 +/- 13.8342\n",
      "\tSubject 9 average accuracy: 79.8165 +/- 10.2947\n",
      "\tAverage accuracy: 72.7768 +/- 14.1315\n",
      "LDA\n",
      "\tSubject 1 average accuracy: 70.8499 +/- 4.7614\n",
      "\tSubject 2 average accuracy: 56.8004 +/- 4.2206\n",
      "\tSubject 3 average accuracy: 55.0721 +/- 9.8510\n",
      "\tSubject 4 average accuracy: 90.2508 +/- 6.0573\n",
      "\tSubject 5 average accuracy: 81.8066 +/- 6.1260\n",
      "\tSubject 6 average accuracy: 76.7726 +/- 4.6265\n",
      "\tSubject 7 average accuracy: 70.5233 +/- 13.1637\n",
      "\tSubject 8 average accuracy: 78.3413 +/- 13.1247\n",
      "\tSubject 9 average accuracy: 81.3766 +/- 5.8507\n",
      "\tAverage accuracy: 73.5326 +/- 13.7155\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(classifier)\n",
    "    for subject, cv_accuracies in enumerate(accuracies[classifier]):\n",
    "        acc_mean = np.mean(cv_accuracies)*100\n",
    "        acc_std = np.std(cv_accuracies)*100\n",
    "        print(f\"\\tSubject {subject+1} average accuracy: {acc_mean:.4f} +/- {acc_std:.4f}\")\n",
    "    average_acc_mean = np.mean(accuracies[classifier])*100\n",
    "    average_acc_std = np.std(accuracies[classifier])*100\n",
    "    print(f\"\\tAverage accuracy: {average_acc_mean:.4f} +/- {average_acc_std:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}