{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/mauricio/development/environments/anaconda3/envs/motor-imagery/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from src.data_preparation.data_preparation import read_eeg_file, get_channels_indexes\n",
    "from scipy import signal\n",
    "from scipy import linalg\n",
    "from scipy.integrate import simps\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pywt\n",
    "import pyriemann.utils.mean as rie_mean\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declaration some parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "FS = 100\n",
    "TIME_LENGTH = 3 * FS\n",
    "TIME_WINDOW = 3 * FS\n",
    "DATA_FOLDER = \"data/specific-band-csp-features/bci-iii-dataset-iv-a\"\n",
    "CSP_COMPONENTS = 8\n",
    "WAVELET = \"coif1\"\n",
    "K_FOLD = 10\n",
    "METRIC_COVARIANCE_ESTIMATION = \"euclid\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the manual channel selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "channels_names = [\"FC2\", \"FC4\", \"FC6\", \"CFC2\", \"CFC4\", \"CFC6\", \"C2\", \"C4\", \"C6\", \n",
    "                  \"CCP2\", \"CCP4\", \"CCP6\", \"CP2\", \"CP4\", \"CP6\", \"FC5\", \"FC3\", \"FC1\", \n",
    "                  \"CFC5\", \"CFC3\", \"CFC1\", \"C5\", \"C3\", \"C1\", \"CCP5\", \"CCP3\", \"CCP1\", \n",
    "                  \"CP5\", \"CP3\" \"CP1\"]\n",
    "channels_indexes = get_channels_indexes(f\"{DATA_FOLDER}/channels_positions.txt\", channels_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the bandpass filter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "sos = signal.cheby2(10, 50, [7, 30], analog=False, btype=\"band\", output=\"sos\", fs=FS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to generate the common spatial filter's based on the test data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_spatial_filters(left_data, right_data):\n",
    "    n_channels = left_data.shape[2]\n",
    "    cov_shape = (n_channels, n_channels)\n",
    "            \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_left_trials = left_data.shape[0]\n",
    "    cov = np.zeros((n_left_trials, *cov_shape))\n",
    "    for n_trial in range(n_left_trials):\n",
    "        trial = signal.sosfilt(sos, left_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_1 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "    \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_right_trials = right_data.shape[0]\n",
    "    cov = np.zeros((n_right_trials, *cov_shape))\n",
    "    for n_trial in range(n_right_trials):\n",
    "        trial = signal.sosfilt(sos, right_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_2 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "    \n",
    "    # Solve the generalized eigenvalue problem\n",
    "    n_pairs = CSP_COMPONENTS//2\n",
    "    w, vr = linalg.eig(cov_1, cov_2, right=True)\n",
    "    w = np.abs(w)\n",
    "    sorted_indexes = np.argsort(w)\n",
    "    chosen_indexes = np.zeros(2*n_pairs).astype(int)\n",
    "    chosen_indexes[0:n_pairs] = sorted_indexes[0:n_pairs]\n",
    "    chosen_indexes[n_pairs:2*n_pairs] = sorted_indexes[-n_pairs:]\n",
    "    \n",
    "    return vr[:, chosen_indexes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    trials = X.shape[0]\n",
    "    F = np.zeros((trials, 2, CSP_COMPONENTS))\n",
    "    for n_trial in range(trials):\n",
    "        x = X[n_trial]\n",
    "        x = signal.sosfilt(sos, x, axis=0)\n",
    "        z = np.dot(np.transpose(W), np.transpose(x))\n",
    "        \n",
    "        # Calculate the wavelet features\n",
    "        for n_feature in range(CSP_COMPONENTS):\n",
    "            alpha_band, beta_band = pywt.dwt(z[n_feature], WAVELET)\n",
    "            F[n_trial, 0, n_feature] = np.sum(np.abs(beta_band) ** 2)\n",
    "\n",
    "        # Calculate the frequency-domain features\n",
    "        psd_window_size = 100\n",
    "        psd_window_overlap = psd_window_size//2\n",
    "        low, high = 13, 30\n",
    "        for n_feature in range(CSP_COMPONENTS):\n",
    "            freqs, psd = signal.welch(z[n_feature], fs=FS, window=\"hann\",\n",
    "                                     nperseg=psd_window_size, noverlap=psd_window_overlap)\n",
    "            beta_freqs = np.logical_and(freqs >= low, freqs <= high)\n",
    "            freq_res = freqs[1] - freqs[0]\n",
    "            F[n_trial, 1, n_feature] = simps(psd[beta_freqs], dx=freq_res)\n",
    "        \n",
    "    return F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterate on the subjects applying the algorithm, \n",
    "validating the results using the technique 10-fold cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Subject:  1\n",
      "Subject:  2\n",
      "Subject:  3\n",
      "Subject:  4\n",
      "Subject:  5\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "subjects = range(1, 6)\n",
    "subjects_set = set(subjects)\n",
    "accuracies = {\n",
    "    \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "}\n",
    "\n",
    "for subject in subjects:\n",
    "    print(\"Subject: \", subject)\n",
    "\n",
    "    # Load data\n",
    "    left_data_file = f\"{DATA_FOLDER}/left-hand-subject-{subject}.csv\"\n",
    "    right_data_file = f\"{DATA_FOLDER}/right-hand-subject-{subject}.csv\"\n",
    "    data = read_eeg_file(left_data_file, right_data_file, TIME_LENGTH, TIME_WINDOW, channels_indexes=channels_indexes)\n",
    "    \n",
    "    W = compute_spatial_filters(data.X[data.labels == 0], data.X[data.labels == 1])\n",
    "    \n",
    "    subject_index = subject - 1\n",
    "    cv = StratifiedKFold(n_splits=K_FOLD, shuffle=True)\n",
    "    for (k, (train_index, test_index)) in enumerate(cv.split(data.X, data.labels)):\n",
    "        X_train, X_test = data.X[train_index], data.X[test_index]\n",
    "        y_train, y_test = data.labels[train_index], data.labels[test_index]\n",
    "        \n",
    "        # Feature extraction\n",
    "        features_train = extract_features(X_train)\n",
    "        features_test = extract_features(X_test)\n",
    "    \n",
    "        len_features = features_train.shape[1] * features_train.shape[2]\n",
    "        features_train = np.reshape(features_train, newshape=(features_train.shape[0], len_features))\n",
    "        features_test = np.reshape(features_test, newshape=(features_test.shape[0], len_features))\n",
    "\n",
    "        # Feature normalization\n",
    "        features_train = stats.zscore(features_train, axis=0)\n",
    "        features_test = stats.zscore(features_test, axis=0)\n",
    "        \n",
    "        # GNB classifier\n",
    "        gnb = GaussianNB(priors=[.5, .5], var_smoothing=1.0)\n",
    "        gnb.fit(features_train, y_train)\n",
    "        gnb_predictions = gnb.predict(features_test)\n",
    "        gnb_accuracy = accuracy_score(y_test, gnb_predictions)\n",
    "        accuracies[\"GNB\"][subject_index][k] = gnb_accuracy\n",
    "\n",
    "        # SVM classifier\n",
    "        svm = SVC(C=.8, kernel=\"rbf\")\n",
    "        svm.fit(features_train, y_train)\n",
    "        svm_predictions = svm.predict(features_test)\n",
    "        svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "        accuracies[\"SVM\"][subject_index][k] = svm_accuracy\n",
    "\n",
    "        # LDA classifier\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(features_train, y_train)\n",
    "        lda_predictions = lda.predict(features_test)\n",
    "        lda_accuracy = accuracy_score(y_test, lda_predictions)\n",
    "        accuracies[\"LDA\"][subject_index][k] = lda_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the accuracies obtained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "GNB\n",
      "\tSubject 1 average accuracy: 81.0714 +/- 6.3987\n",
      "\tSubject 2 average accuracy: 90.3571 +/- 4.5316\n",
      "\tSubject 3 average accuracy: 68.5714 +/- 6.3487\n",
      "\tSubject 4 average accuracy: 88.9286 +/- 5.6356\n",
      "\tSubject 5 average accuracy: 84.6429 +/- 6.9712\n",
      "\tAverage accuracy: 82.7143 +/- 9.8551\n",
      "SVM\n",
      "\tSubject 1 average accuracy: 83.2143 +/- 5.7698\n",
      "\tSubject 2 average accuracy: 94.2857 +/- 4.5737\n",
      "\tSubject 3 average accuracy: 78.9286 +/- 4.6429\n",
      "\tSubject 4 average accuracy: 93.9286 +/- 3.9286\n",
      "\tSubject 5 average accuracy: 90.7143 +/- 6.0187\n",
      "\tAverage accuracy: 88.2143 +/- 7.9299\n",
      "LDA\n",
      "\tSubject 1 average accuracy: 82.1429 +/- 5.2973\n",
      "\tSubject 2 average accuracy: 93.2143 +/- 2.9667\n",
      "\tSubject 3 average accuracy: 73.9286 +/- 7.6682\n",
      "\tSubject 4 average accuracy: 91.7857 +/- 4.2408\n",
      "\tSubject 5 average accuracy: 90.0000 +/- 7.1071\n",
      "\tAverage accuracy: 86.2143 +/- 9.2309\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(classifier)\n",
    "    for subject, cv_accuracies in enumerate(accuracies[classifier]):\n",
    "        acc_mean = np.mean(cv_accuracies)*100\n",
    "        acc_std = np.std(cv_accuracies)*100\n",
    "        print(f\"\\tSubject {subject+1} average accuracy: {acc_mean:.4f} +/- {acc_std:.4f}\")\n",
    "    average_acc_mean = np.mean(accuracies[classifier])*100\n",
    "    average_acc_std = np.std(accuracies[classifier])*100\n",
    "    print(f\"\\tAverage accuracy: {average_acc_mean:.4f} +/- {average_acc_std:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}