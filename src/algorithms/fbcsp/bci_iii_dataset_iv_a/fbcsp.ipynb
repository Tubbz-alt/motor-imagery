{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "from src.data_preparation.data_preparation import read_eeg_file, get_channels_indexes\n",
    "from scipy import signal\n",
    "from scipy import linalg\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.algorithms.fbcsp.MIBIFFeatureSelection import MIBIFFeatureSelection\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pyriemann.utils.mean as rie_mean\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define some parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "FS = 100\n",
    "TIME_LENGTH = 2 * FS\n",
    "TIME_WINDOW = 2 * FS\n",
    "CSP_COMPONENTS = 8\n",
    "DATA_FOLDER = \"data/fbcsp/bci-iii-dataset-iv-a\"\n",
    "K_FOLD = 10\n",
    "METRIC_COVARIANCE_ESTIMATION = \"euclid\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the manual channel selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "channels_names = [\"FC2\", \"FC4\", \"FC6\", \"CFC2\", \"CFC4\", \"CFC6\", \"C2\", \"C4\", \"C6\", \n",
    "                  \"CCP2\", \"CCP4\", \"CCP6\", \"CP2\", \"CP4\", \"CP6\", \"FC5\", \"FC3\", \"FC1\", \n",
    "                  \"CFC5\", \"CFC3\", \"CFC1\", \"C5\", \"C3\", \"C1\", \"CCP5\", \"CCP3\", \"CCP1\", \n",
    "                  \"CP5\", \"CP3\", \"CP1\"]\n",
    "channels_indexes = get_channels_indexes(f\"{DATA_FOLDER}/channels_positions.txt\", channels_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the objects with the bands used by the Filter Bank"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "band_length = 6\n",
    "min_freq = 4\n",
    "max_freq = 40\n",
    "bands = [(x, x+band_length) for x in range(min_freq, max_freq, band_length)]\n",
    "quantity_bands = len(bands)\n",
    "\n",
    "filter_bank = []\n",
    "for (low_freq, high_freq) in bands:\n",
    "    filter_bank.append(signal.cheby2(10, 50, [low_freq, high_freq], analog=False, btype=\"band\", output=\"sos\", fs=FS))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to generate the common spatial filter's based on the test data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def compute_spatial_filters(left_data, right_data, sos):\n",
    "    n_channels = left_data.shape[2]\n",
    "    cov_shape = (n_channels, n_channels)\n",
    "    \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_left_trials = left_data.shape[0]\n",
    "    cov = np.zeros((n_left_trials, *cov_shape))\n",
    "    for n_trial in range(n_left_trials):\n",
    "        trial = signal.sosfilt(sos, left_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_1 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "    \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_right_trials = right_data.shape[0]\n",
    "    cov = np.zeros((n_right_trials, *cov_shape))\n",
    "    for n_trial in range(n_right_trials):\n",
    "        trial = signal.sosfilt(sos, right_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_2 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "    \n",
    "    # Solve the generalized eigenvalue problem\n",
    "    n_pairs = CSP_COMPONENTS//2\n",
    "    w, vr = linalg.eig(cov_1, cov_2, right=True)\n",
    "    w = np.abs(w)\n",
    "    sorted_indexes = np.argsort(w)\n",
    "    chosen_indexes = np.zeros(2*n_pairs).astype(int)\n",
    "    chosen_indexes[0:n_pairs] = sorted_indexes[0:n_pairs]\n",
    "    chosen_indexes[n_pairs:2*n_pairs] = sorted_indexes[-n_pairs:]\n",
    "\n",
    "    return vr[:, chosen_indexes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to apply the spatial filter and extract the features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def extract_features(X, W, sos):\n",
    "    trials = len(X)\n",
    "    F = np.zeros((trials, CSP_COMPONENTS))\n",
    "    for n_trial in range(trials):\n",
    "        x = signal.sosfilt(sos, X[n_trial], axis=0)\n",
    "        z = np.dot(np.transpose(W), np.transpose(x))\n",
    "        F[n_trial] = np.log(np.divide(np.var(z, axis=1), np.sum(np.var(z, axis=1))))\n",
    "        \n",
    "    return F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to process a fold with the following steps:\n",
    "\n",
    "- Split the data into train and test\n",
    "- Generate the spatial filters to each band\n",
    "- Extract the features to train data\n",
    "- Extract the features to test data\n",
    "- Make feature selection on the features\n",
    "- Classify the features using GNB, LDA and SVM algorithms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def process_fold(X, Y, train_index, test_index):\n",
    "    train = {\n",
    "        \"X\": X[train_index],\n",
    "        \"Y\": Y[train_index]\n",
    "    }\n",
    "    train[\"left\"] = train[\"X\"][train[\"Y\"] == 0]\n",
    "    train[\"right\"] = train[\"X\"][train[\"Y\"] == 1]\n",
    "    train[\"trials\"] = train[\"X\"].shape[0]\n",
    "    \n",
    "    test = {\n",
    "        \"X\": X[test_index],\n",
    "        \"Y\": Y[test_index]\n",
    "    }\n",
    "    test[\"left\"] = test[\"X\"][test[\"Y\"] == 0]\n",
    "    test[\"right\"] = test[\"X\"][test[\"Y\"] == 1]\n",
    "    test[\"trials\"] = test[\"X\"].shape[0]\n",
    "\n",
    "    # Feature extraction\n",
    "    spatial_filters = [compute_spatial_filters(train[\"left\"], train[\"right\"], sos)\n",
    "                       for sos in filter_bank]\n",
    "\n",
    "    train[\"F\"] = np.zeros((quantity_bands, train[\"trials\"], CSP_COMPONENTS))\n",
    "    for n_band in range(quantity_bands):\n",
    "        sos = filter_bank[n_band]\n",
    "        W = spatial_filters[n_band]\n",
    "        train[\"F\"][n_band] = extract_features(train[\"X\"], W, sos)\n",
    "    train[\"F\"] = np.concatenate(train[\"F\"], axis=1)\n",
    "    \n",
    "    test[\"F\"] = np.zeros((quantity_bands, test[\"trials\"], CSP_COMPONENTS))\n",
    "    for n_band in range(quantity_bands):\n",
    "        sos = filter_bank[n_band]\n",
    "        W = spatial_filters[n_band]\n",
    "        test[\"F\"][n_band] = extract_features(test[\"X\"], W, sos)\n",
    "    test[\"F\"] = np.concatenate(test[\"F\"], axis=1)\n",
    "    \n",
    "    # Feature Selection\n",
    "    selected_features = MIBIFFeatureSelection(train[\"F\"], test[\"F\"], train[\"Y\"], CSP_COMPONENTS, 4, scale=False)\n",
    "    train[\"F\"] = selected_features.training_features\n",
    "    test[\"F\"] = selected_features.test_features\n",
    "\n",
    "    # GNB classifier\n",
    "    gnb = GaussianNB(priors=[.5, .5])\n",
    "    gnb.fit(train[\"F\"], train[\"Y\"])\n",
    "    gnb_predictions = gnb.predict(test[\"F\"])\n",
    "    gnb_accuracy = accuracy_score(test[\"Y\"], gnb_predictions)\n",
    "\n",
    "    # SVM classifier\n",
    "    svm = SVC(C=.8, gamma=\"scale\", kernel=\"rbf\")\n",
    "    svm.fit(train[\"F\"], train[\"Y\"])\n",
    "    svm_predictions = svm.predict(test[\"F\"])\n",
    "    svm_accuracy = accuracy_score(test[\"Y\"], svm_predictions)\n",
    "\n",
    "    # LDA classifier\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(train[\"F\"], train[\"Y\"])\n",
    "    lda_predictions = lda.predict(test[\"F\"])\n",
    "    lda_accuracy = accuracy_score(test[\"Y\"], lda_predictions)\n",
    "    \n",
    "    return gnb_accuracy, svm_accuracy, lda_accuracy\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the features and classify applying 10 cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Subject:  1\n",
      "Subject:  2\n",
      "Subject:  3\n",
      "Subject:  4\n",
      "Subject:  5\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "subjects = range(1, 6)\n",
    "accuracies = {\n",
    "    \"GNB\": np.zeros(len(subjects)),\n",
    "    \"SVM\": np.zeros(len(subjects)),\n",
    "    \"LDA\": np.zeros(len(subjects))\n",
    "}\n",
    "\n",
    "for subject in subjects:\n",
    "    print(\"Subject: \", subject)\n",
    "\n",
    "    left_data_file = f\"{DATA_FOLDER}/left-hand-subject-{subject}.csv\"\n",
    "    right_data_file = f\"{DATA_FOLDER}/right-hand-subject-{subject}.csv\"\n",
    "    data = read_eeg_file(left_data_file, right_data_file, TIME_LENGTH, TIME_WINDOW, channels_indexes=channels_indexes)\n",
    "    \n",
    "    subject_index = subject - 1\n",
    "    for fold in range(K_FOLD):\n",
    "        k_fold_accuracies = {\n",
    "            \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "            \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "            \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "        }\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=K_FOLD, shuffle=True)\n",
    "        for (k, (train_index, test_index)) in enumerate(cv.split(data.X, data.labels)):\n",
    "            gnb_accuracy, svm_accuracy, lda_accuracy = process_fold(data.X, data.labels, train_index, test_index)\n",
    "            \n",
    "            k_fold_accuracies[\"GNB\"][subject_index][k] = gnb_accuracy\n",
    "            k_fold_accuracies[\"SVM\"][subject_index][k] = svm_accuracy\n",
    "            k_fold_accuracies[\"LDA\"][subject_index][k] = lda_accuracy\n",
    "        \n",
    "        accuracies[\"GNB\"][subject_index] = np.mean(k_fold_accuracies[\"GNB\"][subject_index])\n",
    "        accuracies[\"SVM\"][subject_index] = np.mean(k_fold_accuracies[\"SVM\"][subject_index])\n",
    "        accuracies[\"LDA\"][subject_index] = np.mean(k_fold_accuracies[\"LDA\"][subject_index])\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the accuracies obtained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "GNB\n",
      "\tSubject 1 average accuracy: 86.1111\n",
      "\tSubject 2 average accuracy: 97.9902\n",
      "\tSubject 3 average accuracy: 71.9608\n",
      "\tSubject 4 average accuracy: 96.2582\n",
      "\tSubject 5 average accuracy: 84.3627\n",
      "\tAverage accuracy: 87.3366 +/- 9.3793\n",
      "SVM\n",
      "\tSubject 1 average accuracy: 85.4412\n",
      "\tSubject 2 average accuracy: 98.8562\n",
      "\tSubject 3 average accuracy: 71.0784\n",
      "\tSubject 4 average accuracy: 96.5686\n",
      "\tSubject 5 average accuracy: 83.7582\n",
      "\tAverage accuracy: 87.1405 +/- 9.9846\n",
      "LDA\n",
      "\tSubject 1 average accuracy: 84.6405\n",
      "\tSubject 2 average accuracy: 97.9902\n",
      "\tSubject 3 average accuracy: 69.3301\n",
      "\tSubject 4 average accuracy: 95.3922\n",
      "\tSubject 5 average accuracy: 84.5915\n",
      "\tAverage accuracy: 86.3889 +/- 10.1286\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for classifier in accuracies:\n",
    "    print(classifier)\n",
    "    for subject, accuracy in enumerate(accuracies[classifier]):\n",
    "        print(f\"\\tSubject {subject+1} average accuracy: {accuracy*100:.4f}\")\n",
    "    average_acc_mean = np.mean(accuracies[classifier]) * 100\n",
    "    average_acc_std = np.std(accuracies[classifier]) * 100\n",
    "    print(f\"\\tAverage accuracy: {average_acc_mean:.4f} +/- {average_acc_std:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}