{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/mauricio/development/environments/anaconda3/envs/motor-imagery/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from src.data_preparation.data_preparation import read_eeg_file\n",
    "from scipy import signal\n",
    "from scipy import linalg\n",
    "from scipy import stats\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pyriemann.utils.mean as rie_mean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define some parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "FS = 100\n",
    "TIME_LENGTH = int(FS * 2.5)\n",
    "TIME_WINDOW = int(FS * 2.5)\n",
    "DATA_FOLDER = \"data/si-bci/bci-iii-dataset-iv-a\"\n",
    "CSP_COMPONENTS = 8\n",
    "METRIC_COVARIANCE_ESTIMATION = \"logeuclid\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a fifth Butterworth bandpass filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "sos = signal.butter(5, [8, 30], analog=False, btype=\"band\", output=\"sos\", fs=FS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to compute the spatial filters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def compute_spatial_filters(left_data, right_data):\n",
    "    n_channels = left_data.shape[2]\n",
    "    cov_shape = (n_channels, n_channels)\n",
    "\n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_left_trials = left_data.shape[0]\n",
    "    cov = np.zeros((n_left_trials, *cov_shape))\n",
    "    for n_trial in range(n_left_trials):\n",
    "        trial = signal.sosfilt(sos, left_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_1 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "\n",
    "    # Estimate the covariance matrix of every trial\n",
    "    n_right_trials = right_data.shape[0]\n",
    "    cov = np.zeros((n_right_trials, *cov_shape))\n",
    "    for n_trial in range(n_right_trials):\n",
    "        trial = signal.sosfilt(sos, right_data[n_trial], axis=0)\n",
    "        cov[n_trial] = np.cov(np.transpose(trial))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_2 = rie_mean.mean_covariance(cov, metric=METRIC_COVARIANCE_ESTIMATION)\n",
    "\n",
    "    # Solve the generalized eigenvalue problem\n",
    "    n_pairs = CSP_COMPONENTS // 2\n",
    "    w, vr = linalg.eig(cov_1, cov_2, right=True)\n",
    "    w = np.abs(w)\n",
    "    sorted_indexes = np.argsort(w)\n",
    "    chosen_indexes = np.zeros(2 * n_pairs).astype(int)\n",
    "    chosen_indexes[0:n_pairs] = sorted_indexes[0:n_pairs]\n",
    "    chosen_indexes[n_pairs:2 * n_pairs] = sorted_indexes[-n_pairs:]\n",
    "\n",
    "    return vr[:, chosen_indexes]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to extract the log variance and katz fractal dimension features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def extract_features(left_data, right_data):\n",
    "    W = compute_spatial_filters(left_data, right_data)\n",
    "\n",
    "    X = np.concatenate((left_data, right_data))\n",
    "    n_trials = X.shape[0]\n",
    "    features = {\n",
    "        \"CSP\": np.zeros((n_trials, CSP_COMPONENTS)),\n",
    "        \"KATZ_FRACTAL\": np.zeros((n_trials, CSP_COMPONENTS))\n",
    "    }\n",
    "\n",
    "    for n_trial in range(n_trials):\n",
    "        x = X[n_trial]\n",
    "        x = signal.sosfilt(sos, x, axis=0)\n",
    "        z = np.dot(np.transpose(W), np.transpose(x))\n",
    "        features[\"CSP\"][n_trial] = np.log(np.divide(np.var(z, axis=1), np.sum(np.var(z, axis=1))))\n",
    "        for n_component in range(CSP_COMPONENTS):\n",
    "            features[\"KATZ_FRACTAL\"][n_trial, n_component] = katz_fractal(z[n_component])\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to compute the katz fractal dimension feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def katz_fractal(x):\n",
    "    n = len(x) - 1\n",
    "\n",
    "    # Calculate the total length L of the signal\n",
    "    L = 0\n",
    "    for n_i in range(n):\n",
    "        # Use the Euclidean distance formula to obtain the distance between the consecutive points\n",
    "        x_distance = 1\n",
    "        y_distance = (x[n_i] - x[n_i + 1]) ** 2\n",
    "        L = L + np.sqrt(x_distance + y_distance)\n",
    "\n",
    "    # Calculate the diameter of the signal, that is the farthest distance between the starting point to any other point\n",
    "    d = np.zeros(n)\n",
    "    for n_i in range(n):\n",
    "        # Use the Euclidean distance formula to obtain the distance between the points to the origin\n",
    "        x_distance = (n_i + 1) ** 2\n",
    "        y_distance = (x[0] - x[n_i + 1]) ** 2\n",
    "        d[n_i] = np.sqrt(x_distance + y_distance)\n",
    "    d = np.max(d)\n",
    "\n",
    "    ln = np.log10(n)\n",
    "    return ln / (np.log10(d / L) + ln)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the functions to make the predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def lda_prediction_score(X_train, Y_train, X_test, Y_test):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_train, Y_train)\n",
    "    predictions = lda.predict(X_test)\n",
    "    return accuracy_score(Y_test, predictions)\n",
    "\n",
    "def svm_prediction_score(X_train, Y_train, X_test, Y_test):\n",
    "    svm = SVC(C=.8, gamma=\"scale\", kernel=\"rbf\")\n",
    "    svm.fit(X_train, Y_train)\n",
    "    predictions = svm.predict(X_test)\n",
    "    return accuracy_score(Y_test, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate the spatial filters separately for each subject,\n",
    "and extract the features.\n",
    "\n",
    "The algorithm uses 4 subjects for train, and 1 subject for test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Subject:  1\n",
      "Subject:  2\n",
      "Subject:  3\n",
      "Subject:  4\n",
      "Subject:  5\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "subjects = range(1, 6)\n",
    "subjects_set = set(subjects)\n",
    "accuracies = {\n",
    "    \"SVM\": {\n",
    "        \"CSP\": np.zeros(len(subjects)),\n",
    "        \"KATZ_FRACTAL\": np.zeros(len(subjects))\n",
    "    },\n",
    "    \"LDA\": {\n",
    "        \"CSP\": np.zeros(len(subjects)),\n",
    "        \"KATZ_FRACTAL\": np.zeros(len(subjects))\n",
    "    }\n",
    "}\n",
    "\n",
    "for test_subject in subjects:\n",
    "    print(\"Subject: \", test_subject)\n",
    "    train_subjects = list(subjects_set - {test_subject})\n",
    "\n",
    "    # Load training data\n",
    "    path_train_files = [(f\"{DATA_FOLDER}/left-hand-subject-{train_subject}.csv\",\n",
    "                        f\"{DATA_FOLDER}/right-hand-subject-{train_subject}.csv\")\n",
    "                        for train_subject in train_subjects]\n",
    "    train_data_by_subject = [read_eeg_file(left_data_file, right_data_file, TIME_LENGTH, TIME_WINDOW)\n",
    "                             for left_data_file, right_data_file in path_train_files]\n",
    "\n",
    "    # Load test data\n",
    "    left_data_file = f\"{DATA_FOLDER}/left-hand-subject-{test_subject}.csv\"\n",
    "    right_data_file = f\"{DATA_FOLDER}/right-hand-subject-{test_subject}.csv\"\n",
    "    test_data = read_eeg_file(left_data_file, right_data_file, TIME_LENGTH, TIME_WINDOW, training=False)\n",
    "\n",
    "    train_data = {\n",
    "        \"Y\": [],\n",
    "        \"CSP\": None,\n",
    "        \"KATZ_FRACTAL\": None\n",
    "    }\n",
    "    for (i, train_data_subject) in enumerate(train_data_by_subject):\n",
    "        train_data_subject.left_data = signal.sosfilt(sos, train_data_subject.left_data, axis=1)\n",
    "        train_data_subject.right_data = signal.sosfilt(sos, train_data_subject.right_data, axis=1)\n",
    "\n",
    "        train_data[\"Y\"] = np.concatenate((train_data[\"Y\"], train_data_subject.labels))\n",
    "        train_features = extract_features(train_data_subject.left_data, train_data_subject.right_data)\n",
    "        if i == 0:\n",
    "            train_data[\"CSP\"] = train_features[\"CSP\"]\n",
    "            train_data[\"KATZ_FRACTAL\"] = train_features[\"KATZ_FRACTAL\"]\n",
    "        else:\n",
    "            train_data[\"CSP\"] = np.concatenate((train_data[\"CSP\"], train_features[\"CSP\"]))\n",
    "            train_data[\"KATZ_FRACTAL\"] = np.concatenate((train_data[\"KATZ_FRACTAL\"], train_features[\"KATZ_FRACTAL\"]))\n",
    "\n",
    "    test_data.F = extract_features(test_data.left_data, test_data.right_data)\n",
    "\n",
    "    # Normalize the features\n",
    "    train_data[\"CSP\"] = stats.zscore(train_data[\"CSP\"], axis=0)\n",
    "    train_data[\"KATZ_FRACTAL\"] = stats.zscore(train_data[\"KATZ_FRACTAL\"], axis=0)\n",
    "    test_data.F[\"CSP\"] = stats.zscore(test_data.F[\"CSP\"], axis=0)\n",
    "    test_data.F[\"KATZ_FRACTAL\"] = stats.zscore(test_data.F[\"KATZ_FRACTAL\"], axis=0)\n",
    "\n",
    "    accuracy_index = test_subject - 1\n",
    "    csp_parameters = (train_data[\"CSP\"], train_data[\"Y\"], test_data.F[\"CSP\"], test_data.labels)\n",
    "    katz_fractal_parameters = (train_data[\"KATZ_FRACTAL\"], train_data[\"Y\"], \n",
    "                               test_data.F[\"KATZ_FRACTAL\"], test_data.labels)\n",
    "    accuracies[\"SVM\"][\"CSP\"][accuracy_index] = svm_prediction_score(*csp_parameters)\n",
    "    accuracies[\"SVM\"][\"KATZ_FRACTAL\"][accuracy_index] = svm_prediction_score(*katz_fractal_parameters)\n",
    "    accuracies[\"LDA\"][\"CSP\"][accuracy_index] = lda_prediction_score(*csp_parameters)\n",
    "    accuracies[\"LDA\"][\"KATZ_FRACTAL\"][accuracy_index] = lda_prediction_score(*katz_fractal_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the accuracies obtained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "=========================\n",
      "SVM\n",
      "\n",
      "CSP\n",
      "\tSubject 1 average accuracy: 90.3571\n",
      "\tSubject 2 average accuracy: 95.3571\n",
      "\tSubject 3 average accuracy: 66.0714\n",
      "\tSubject 4 average accuracy: 95.0000\n",
      "\tSubject 5 average accuracy: 93.9286\n",
      "\tAverage accuracy: 88.1429 +/- 11.1767\n",
      "\n",
      "KATZ_FRACTAL\n",
      "\tSubject 1 average accuracy: 90.3571\n",
      "\tSubject 2 average accuracy: 96.0714\n",
      "\tSubject 3 average accuracy: 73.9286\n",
      "\tSubject 4 average accuracy: 95.0000\n",
      "\tSubject 5 average accuracy: 95.7143\n",
      "\tAverage accuracy: 90.2143 +/- 8.3989\n",
      "\n",
      "=========================\n",
      "LDA\n",
      "\n",
      "CSP\n",
      "\tSubject 1 average accuracy: 90.0000\n",
      "\tSubject 2 average accuracy: 92.5000\n",
      "\tSubject 3 average accuracy: 66.4286\n",
      "\tSubject 4 average accuracy: 93.9286\n",
      "\tSubject 5 average accuracy: 95.0000\n",
      "\tAverage accuracy: 87.5714 +/- 10.7033\n",
      "\n",
      "KATZ_FRACTAL\n",
      "\tSubject 1 average accuracy: 90.7143\n",
      "\tSubject 2 average accuracy: 95.0000\n",
      "\tSubject 3 average accuracy: 76.0714\n",
      "\tSubject 4 average accuracy: 95.3571\n",
      "\tSubject 5 average accuracy: 97.1429\n",
      "\tAverage accuracy: 90.8571 +/- 7.6884\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for classifier_algorithm in accuracies.keys():\n",
    "    print(\"=========================\")\n",
    "    print(f\"{classifier_algorithm}\\n\")\n",
    "    for feature_extraction_method in accuracies[classifier_algorithm].keys():\n",
    "        print(feature_extraction_method)\n",
    "        for subject, cv_accuracies in enumerate(accuracies[classifier_algorithm][feature_extraction_method]):\n",
    "            acc_mean = np.mean(cv_accuracies) * 100\n",
    "            print(f\"\\tSubject {subject + 1} average accuracy: {acc_mean:.4f}\")\n",
    "        average_acc_mean = np.mean(accuracies[classifier_algorithm][feature_extraction_method]) * 100\n",
    "        average_acc_std = np.std(accuracies[classifier_algorithm][feature_extraction_method]) * 100\n",
    "        print(f\"\\tAverage accuracy: {average_acc_mean:.4f} +/- {average_acc_std:.4f}\")\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}