{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/mauricio/development/environments/anaconda3/envs/motor-imagery/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from src.data_preparation.data_preparation import read_eeg_file\n",
    "from src.data_preparation.data_preparation import EEG\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import linalg\n",
    "import pyriemann.utils.mean as rie_mean\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the constants with parameters to apply the algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "FS = 100\n",
    "TIME_LENGTH = 2 * FS\n",
    "TIME_WINDOW = 2 * FS\n",
    "EPOCH_SIZE = None\n",
    "DATA_FOLDER = \"data/csp/bci-iii-dataset-iv-a/subject-independent\"\n",
    "CSP_COMPONENTS = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the objects to store the evaluation data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "K_FOLD = 10\n",
    "subjects = range(1, 6)\n",
    "accuracies = {\n",
    "    \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "}\n",
    "\n",
    "final_accuracies = {\n",
    "    \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "}\n",
    "\n",
    "misclassification_rate = {\n",
    "    \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "}\n",
    "\n",
    "final_misclassification_rate = {\n",
    "    \"GNB\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"SVM\": np.zeros((len(subjects), K_FOLD)),\n",
    "    \"LDA\": np.zeros((len(subjects), K_FOLD))\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the bandpass filter to be used in the pre-processing step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sos = signal.butter(5, [7, 30], analog=False, btype=\"band\", output=\"sos\", fs=FS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the EEG data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data = []\n",
    "for subject in subjects:\n",
    "    left_data_file = f\"{DATA_FOLDER}/left-hand-subject-{subject}.csv\"\n",
    "    right_data_file = f\"{DATA_FOLDER}/right-hand-subject-{subject}.csv\"\n",
    "    data.append(read_eeg_file(left_data_file, right_data_file, TIME_LENGTH, TIME_WINDOW, EPOCH_SIZE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to generate the common spatial filter's based on the test data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_spatial_filters(train_data):\n",
    "    cov_shape = (train_data.n_channels, train_data.n_channels)\n",
    "    \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    cov = np.zeros((train_data.n_left_trials, *cov_shape))\n",
    "    for n_trial in range(train_data.n_left_trials):\n",
    "        trial_filtered = signal.sosfilt(sos, train_data.left_data[n_trial], axis=0)\n",
    "        cov[n_trial,:,:] = np.cov(np.transpose(trial_filtered))\n",
    "\n",
    "    # calculate average of covariance matrix\n",
    "    cov_1 = rie_mean.mean_covariance(cov, metric=\"riemann\")\n",
    "    \n",
    "    # Estimate the covariance matrix of every trial\n",
    "    cov = np.zeros((train_data.n_right_trials, *cov_shape))\n",
    "    for n_trial in range(train_data.n_right_trials):\n",
    "        trial_filtered = signal.sosfilt(sos, train_data.right_data[n_trial], axis=0)\n",
    "        cov[n_trial,:,:] = np.cov(np.transpose(trial_filtered))\n",
    "        \n",
    "    # calculate average of covariance matrix\n",
    "    cov_2 = rie_mean.mean_covariance(cov, metric=\"riemann\")\n",
    "    \n",
    "    # Solve the generalized eigenvalue problem\n",
    "    n_pairs = CSP_COMPONENTS//2\n",
    "    w, vr = linalg.eig(cov_1, cov_2, right=True)\n",
    "    w = np.abs(w)\n",
    "    sorted_indexes = np.argsort(w)\n",
    "    chosen_indexes = np.zeros(2*n_pairs).astype(int)\n",
    "    chosen_indexes[0:n_pairs] = sorted_indexes[0:n_pairs]\n",
    "    chosen_indexes[n_pairs:2*n_pairs] = sorted_indexes[-n_pairs:]\n",
    "\n",
    "    return vr[:, chosen_indexes]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the function to apply the spatial filter and extract the features "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def extract_features(X, W):\n",
    "    trials = len(X)\n",
    "    F = np.zeros((trials, CSP_COMPONENTS))\n",
    "    for n_trial in range(trials):\n",
    "        trial = X[n_trial]\n",
    "        Z = np.dot(np.transpose(W), np.transpose(trial))\n",
    "        Z = signal.sosfilt(sos, Z, axis=1)\n",
    "        F[n_trial] = np.log(np.divide(np.var(Z, axis=1), np.sum(np.var(Z, axis=1))))\n",
    "        \n",
    "    return F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iterate on the subjects applying the algorithm, \n",
    "validating the results using the technique 10x10-fold cross-validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Subject 1 ...\n",
      "Subject 2 ...\n",
      "Subject 3 ...\n",
      "Subject 4 ...\n",
      "Subject 5 ...\n",
      "\n",
      "Accuracy\n",
      "GNB\n",
      "\tSubject 1 average accuracy: 0.7493 +/- 0.0126\n",
      "\tSubject 2 average accuracy: 0.9614 +/- 0.0038\n",
      "\tSubject 3 average accuracy: 0.6575 +/- 0.0111\n",
      "\tSubject 4 average accuracy: 0.7771 +/- 0.0178\n",
      "\tSubject 5 average accuracy: 0.9361 +/- 0.0067\n",
      "\tAverage accuracy: 0.8163 +/- 0.1160\n",
      "SVM\n",
      "\tSubject 1 average accuracy: 0.7700 +/- 0.0092\n",
      "\tSubject 2 average accuracy: 0.9636 +/- 0.0027\n",
      "\tSubject 3 average accuracy: 0.6757 +/- 0.0153\n",
      "\tSubject 4 average accuracy: 0.8018 +/- 0.0113\n",
      "\tSubject 5 average accuracy: 0.9321 +/- 0.0075\n",
      "\tAverage accuracy: 0.8286 +/- 0.1067\n",
      "LDA\n",
      "\tSubject 1 average accuracy: 0.7921 +/- 0.0130\n",
      "\tSubject 2 average accuracy: 0.9621 +/- 0.0024\n",
      "\tSubject 3 average accuracy: 0.6807 +/- 0.0134\n",
      "\tSubject 4 average accuracy: 0.7996 +/- 0.0092\n",
      "\tSubject 5 average accuracy: 0.9357 +/- 0.0051\n",
      "\tAverage accuracy: 0.8341 +/- 0.1036\n",
      "\n",
      "Misclassification\n",
      "GNB\n",
      "\tSubject 1 misclassification rate: 0.2507 +/- 0.0126\n",
      "\tSubject 2 misclassification rate: 0.0386 +/- 0.0038\n",
      "\tSubject 3 misclassification rate: 0.3425 +/- 0.0111\n",
      "\tSubject 4 misclassification rate: 0.2229 +/- 0.0178\n",
      "\tSubject 5 misclassification rate: 0.0639 +/- 0.0067\n",
      "\tMisclassification rate: 0.1836 +/- 0.1338\n",
      "SVM\n",
      "\tSubject 1 misclassification rate: 0.2300 +/- 0.0092\n",
      "\tSubject 2 misclassification rate: 0.0364 +/- 0.0027\n",
      "\tSubject 3 misclassification rate: 0.3243 +/- 0.0153\n",
      "\tSubject 4 misclassification rate: 0.1982 +/- 0.0113\n",
      "\tSubject 5 misclassification rate: 0.0679 +/- 0.0075\n",
      "\tMisclassification rate: 0.1750 +/- 0.1200\n",
      "LDA\n",
      "\tSubject 1 misclassification rate: 0.2079 +/- 0.0130\n",
      "\tSubject 2 misclassification rate: 0.0379 +/- 0.0024\n",
      "\tSubject 3 misclassification rate: 0.3193 +/- 0.0134\n",
      "\tSubject 4 misclassification rate: 0.2004 +/- 0.0092\n",
      "\tSubject 5 misclassification rate: 0.0643 +/- 0.0051\n",
      "\tMisclassification rate: 0.1700 +/- 0.1211\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    print(f\"Subject {subject} ...\")\n",
    "    subject_index = subject - 1\n",
    "    subject_data = data[subject_index]\n",
    "\n",
    "    for fold in range(K_FOLD):\n",
    "        cv = StratifiedKFold(n_splits=K_FOLD, shuffle=True)\n",
    "        for (k, (train_index, test_index)) in enumerate(cv.split(subject_data.X, subject_data.labels)):\n",
    "            X_train, X_test = subject_data.X[train_index], subject_data.X[test_index]\n",
    "            y_train, y_test = subject_data.labels[train_index], subject_data.labels[test_index]\n",
    "            \n",
    "            train_data = EEG(X_train[y_train == 0], X_train[y_train == 1])\n",
    "            test_data = EEG(X_test[y_test == 0], X_test[y_test == 1], False)\n",
    "            \n",
    "            W = compute_spatial_filters(train_data)\n",
    "    \n",
    "            features = dict({\n",
    "                \"train\": extract_features(train_data.X, W),\n",
    "                \"test\": extract_features(test_data.X, W)\n",
    "            })\n",
    "            \n",
    "            # GNB classifier\n",
    "            gnb = GaussianNB()\n",
    "            gnb.fit(features[\"train\"], y_train)\n",
    "            gnb_predictions = gnb.predict(features[\"test\"])\n",
    "            accuracies[\"GNB\"][subject_index][k] = accuracy_score(y_test, gnb_predictions)\n",
    "            misclassification_rate[\"GNB\"][subject_index][k] = zero_one_loss(y_test, gnb_predictions)\n",
    "    \n",
    "            # SVM classifier\n",
    "            svm = SVC(C=.8, kernel=\"rbf\", gamma=\"scale\")\n",
    "            svm.fit(features[\"train\"], y_train)\n",
    "            svm_predictions = svm.predict(features[\"test\"])\n",
    "            accuracies[\"SVM\"][subject_index][k] = accuracy_score(y_test, svm_predictions)\n",
    "            misclassification_rate[\"SVM\"][subject_index][k] = zero_one_loss(y_test, svm_predictions)\n",
    "    \n",
    "            # LDA classifier\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            lda.fit(features[\"train\"], y_train)\n",
    "            lda_predictions = lda.predict(features[\"test\"])\n",
    "            accuracies[\"LDA\"][subject_index][k] = accuracy_score(y_test, lda_predictions)\n",
    "            misclassification_rate[\"LDA\"][subject_index][k] = zero_one_loss(y_test, lda_predictions)\n",
    "            \n",
    "        # Average the accuracies of one single fold cv\n",
    "        for classifier in accuracies:\n",
    "            final_accuracies[classifier][subject_index][fold] = np.mean(accuracies[classifier][subject_index])\n",
    "            final_misclassification_rate[classifier][subject_index][fold] = np.mean(misclassification_rate[classifier][subject_index])\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "for classifier in final_accuracies:\n",
    "    print(classifier)\n",
    "    for subject, cv_accuracies in enumerate(final_accuracies[classifier]):\n",
    "        acc_mean = np.mean(cv_accuracies)\n",
    "        acc_std = np.std(cv_accuracies)\n",
    "        print(f\"\\tSubject {subject+1} average accuracy: {acc_mean:.4f} +/- {acc_std:.4f}\")\n",
    "    average_acc_mean = np.mean(final_accuracies[classifier])\n",
    "    average_acc_std = np.std(final_accuracies[classifier])\n",
    "    print(f\"\\tAverage accuracy: {average_acc_mean:.4f} +/- {average_acc_std:.4f}\")\n",
    "\n",
    "print(\"\\nMisclassification\")\n",
    "for classifier in final_misclassification_rate:\n",
    "    print(classifier)\n",
    "    for subject, cv_misclassification_rate in enumerate(final_misclassification_rate[classifier]):\n",
    "        misclassification_rate_mean = np.mean(cv_misclassification_rate)\n",
    "        misclassification_rate_std = np.std(cv_misclassification_rate)\n",
    "        print(f\"\\tSubject {subject+1} misclassification rate: {misclassification_rate_mean:.4f} +/- {misclassification_rate_std:.4f}\")\n",
    "    average_misclassification_rate_mean = np.mean(misclassification_rate[classifier])\n",
    "    average_misclassification_rate_std = np.std(misclassification_rate[classifier])\n",
    "    print(f\"\\tMisclassification rate: {average_misclassification_rate_mean:.4f} +/- {average_misclassification_rate_std:.4f}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}